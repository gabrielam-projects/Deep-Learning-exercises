{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output (Weighted Sum): tensor([[0.5749, 0.4251, 0.0787]])\n",
      "Attention Weights:\n",
      " tensor([[0.5749, 0.2125, 0.2125]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Función para calcular la atención\n",
    "def attention_mechanism(queries, keys, values):\n",
    "    # Calcular similitudes usando distancia coseno\n",
    "    sim_scores = F.cosine_similarity(queries.unsqueeze(1), keys.unsqueeze(0), dim=2)\n",
    "    \n",
    "    # Aplicar softmax para obtener pesos de atención\n",
    "    attention_weights = F.softmax(sim_scores, dim=1)\n",
    "    \n",
    "    # Calcular la salida ponderada\n",
    "    output = torch.bmm(attention_weights.unsqueeze(1), values.unsqueeze(0)).squeeze(1)\n",
    "    return output, attention_weights\n",
    "\n",
    "# Representaciones de palabras (ejemplo simplificado)\n",
    "# En un caso real, usarías embeddings preentrenados (Word2Vec, GloVe, etc.)\n",
    "word_vectors = {\n",
    "    \"happy\": torch.tensor([1.0, 0.0, 0.0]),\n",
    "    \"joyful\": torch.tensor([1.0, 0.0, 0.1]),\n",
    "    \"sad\": torch.tensor([0.0, 1.0, 0.0]),\n",
    "    \"unhappy\": torch.tensor([0.0, 1.0, 0.1])\n",
    "}\n",
    "\n",
    "# Consultas, Claves y Valores\n",
    "queries = word_vectors[\"happy\"].unsqueeze(0)  # Consulta: \"happy\"\n",
    "keys = torch.stack([word_vectors[\"joyful\"], word_vectors[\"sad\"], word_vectors[\"unhappy\"]])  # Claves\n",
    "values = torch.stack([word_vectors[\"joyful\"], word_vectors[\"sad\"], word_vectors[\"unhappy\"]])  # Valores\n",
    "\n",
    "# Calcular la salida y los pesos de atención\n",
    "output, attention_weights = attention_mechanism(queries, keys, values)\n",
    "\n",
    "# Resultados\n",
    "print(\"Output (Weighted Sum):\", output)\n",
    "print(\"Attention Weights:\\n\", attention_weights)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
